# ğŸ• Pizza Review RAG Chatbot

Un assistant intelligent capable de rÃ©pondre Ã  toutes les questions concernant une pizzeria, en s'appuyant sur des avis clients pertinents issus dâ€™un fichier CSV.  
Ce projet utilise le concept de **Retrieval-Augmented Generation (RAG)** avec **LangChain**, **Ollama** (modÃ¨le LLaMA 3), **ChromaDB** pour lâ€™indexation vectorielle, et **Flask** pour lâ€™interface web.

---

## ğŸš€ FonctionnalitÃ©s

- ğŸ” Recherche intelligente dans des avis de clients (RAG)
- ğŸ¤– GÃ©nÃ©ration de rÃ©ponses contextuelles avec un modÃ¨le LLM local (`llama3.2`)
- ğŸ§  Vectorisation des documents avec `nomic-embed-text` via Ollama
- ğŸ’¬ Interface web conversationnelle avec historique de chat
- â™»ï¸ Bouton "Nouveau chat" pour rÃ©initialiser la session

---

## ğŸ“ Arborescence du projet

```
â”œâ”€â”€ app.py                         # Application Flask principale
â”œâ”€â”€ vector.py                      # Construction de la base vectorielle avec LangChain & Chroma
â”œâ”€â”€ realistic_restaurant_reviews.csv  # Base d'avis clients
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                 # Interface utilisateur HTML
â”œâ”€â”€ chrome_langchain_db/          # Dossier gÃ©nÃ©rÃ© contenant la base Chroma persistÃ©e
â””â”€â”€ README.md
```

---

## ğŸ§© Technologies utilisÃ©es

| Composant       | Description                                         |
|-----------------|-----------------------------------------------------|
| ğŸ§  LangChain     | Orchestration du RAG et du prompt                  |
| ğŸ§Š ChromaDB       | Vector store local pour les documents              |
| ğŸ“„ Ollama         | ExÃ©cution locale du LLM (LLaMA 3.2 et embeddings) |
| ğŸŒ Flask          | Interface web minimale mais efficace               |
| ğŸ“Š Pandas         | Chargement et traitement du CSV                   |

---

## âš™ï¸ Installation

1. **PrÃ©-requis** :
   - Python 3.9+
   - [Ollama](https://ollama.com) installÃ© et lancÃ© (`ollama run llama3`)
   - Modules Python suivants :

```bash
pip install flask langchain langchain-community langchain-core langchain-chroma langchain-ollama pandas
```

2. **Lancer le serveur** :

```bash
python app.py
```

3. AccÃ©der Ã  l'interface via :  
ğŸ‘‰ `http://127.0.0.1:5000/`

---

## ğŸ§ª Exemple d'utilisation

Posez des questions comme :

- _â€œQue pensent les clients de la pÃ¢te Ã  pizza ?â€_  
- _â€œLes livraisons sont-elles ponctuelles ?â€_  
- _â€œQuelles sont les critiques les plus frÃ©quentes ?â€_

Le chatbot utilise les 5 avis les plus pertinents pour gÃ©nÃ©rer sa rÃ©ponse.

---

## ğŸ”„ RÃ©initialisation

Cliquez sur **â€œNouveau Chatâ€** pour effacer l'historique et dÃ©marrer une nouvelle conversation.

---

## ğŸ“Œ Personnalisation

- **ModÃ¨le utilisÃ©** : dans `app.py`, vous pouvez changer `llama3.2` par tout autre modÃ¨le compatible Ollama.
- **Nombre de documents rÃ©cupÃ©rÃ©s** : changez `k=5` dans `retriever = vector_store.as_retriever(...)`.
- **Prompt systÃ¨me** : modifiez la variable `template` pour ajuster lâ€™"identitÃ©" du chatbot.

---

## ğŸ“ DonnÃ©es

Les avis sont stockÃ©s dans un fichier CSV nommÃ© `realistic_restaurant_reviews.csv` avec les colonnes :

- `Title` â€“ titre de lâ€™avis
- `Review` â€“ texte complet
- `Rating` â€“ note de lâ€™auteur
- `Date` â€“ date de lâ€™avis

---

## ğŸ“œ Licence

Projet personnel rÃ©alisÃ© Ã  des fins Ã©ducatives.  
N'hÃ©sitez pas Ã  le forker et Ã  lâ€™adapter Ã  dâ€™autres contextes mÃ©tiers.

---
